---
hide: false
title: "Artificial intelligence: a brief on risks and opportunities"
date: 2023-05-30T12:22:37.144Z
featuredImage: 21.png
authors:
  - name: Jacob Arbeid
    page: jacob-arbeid/index
  - name: Konrad Seifert
    page: konrad-seifert/index
isHighlighted: false
---
The last few years have witnessed striking progress in artificial intelligence, driven by the machine learning revolution. However, as ChatGPT foreshadows, humanity is not prepared to govern extremely powerful AI systems as it remains difficult to understand their functioning and direct their influence.

To assist international policy actors in the development of sustainable technological development, we’re publishing this short guide to recent developments in artificial intelligence.

### Risks & opportunities from artificial intelligence

**1-sentence summary:** Artificial Intelligence (AI) has transformative potential for personal well-being, economic growth, and scientific advancement, but risks of misaligned systems range from exacerbated inequality to loss of human control, with solutions including research, auditing, and standard-setting.

**Definitions:** AI is the science of building systems that perform cognitive tasks similar to humans. Recent advances have been due to [](https://www.ibm.com/topics/machine-learning)reinforcement learning, a subset of [machine learning](https://www.ibm.com/topics/machine-learning). 

**The technical details: how artificial intelligence (specifically machine learning) works:**

* For the most advanced systems,  AI = algorithms + compute + data
* Algorithms convert data into useful outputs and allow the system to learn. AI algorithms have [not advanced much](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) since 2018. [Transformers](https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/) were a big step forward.
* Data is the information used to train the system. More data = better systems. 
* Computing power or [‘compute’](https://openai.com/research/ai-and-compute) constitutes the chips used to run the systems. AI chips are difficult to build and have a [complicated supply chain](https://www.tsmc.com/english/aboutTSMC/dc_infographics_supplychain).
* Recently, most advances have come from using more compute. Scaling compute leads to [emergent AI properties](https://cims.nyu.edu/~sbowman/eightthings.pdf) (i.e unpredictable advances). This also means the cost of developing AI is rapidly rising, though the potential for profits is too. 
* AI is a [‘black box’.](https://www.nature.com/articles/d41586-022-00858-1) The iterative process of AI system development means it is currently impossible to know what is happening within and to align the system with human requirements. There are two types of misalignment:

  * [Outer misalignment:](https://en.wikipedia.org/wiki/AI_alignment#Learning_human_values_and_preferences) humans cannot specify goals to the AI that match our aims;
  * [Inner misalignment:](https://en.wikipedia.org/wiki/AI_alignment#Inner_alignment_and_emergent_goals) AI ‘evolves’ undesired goals through reinforcement learning.
* Currently, the most advanced systems are ‘large language models’ (e.g. the system underlying ChatGPT). Such ‘foundation models’ are extensively trained on large datasets and human feedback and can then be used in diverse applications. 

**The international AI landscape:**

* The most advanced systems are concentrated among a few big companies, but once a system has been trained, it is [cheap to proliferate it](https://rethinkpriorities.org/publications/background-for-understanding-the-diffusion-of-large-language-models) on consumer technology. 
* There have been [numerous](https://oecd.ai/en/wonk/documents/g20-ai-principles) [international](https://oecd.ai/en/ai-principles) [attempts](https://www.iso.org/committee/6794475.html) at AI ethics standards, with little implementation.
* The [EU AI Act](https://artificialintelligenceact.eu) is the leading attempt to legislate safe AI systems.

**Opportunities from AI:**

* [Economic growth](https://globalprioritiesinstitute.org/philip-trammell-and-anton-korinek-economic-growth-under-transformative-ai/) through increased productivity
* [Scientific advancement](https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/) leading to better medicine, solar panels etc.
* [Better mediation tools](https://www.nature.com/articles/s41562-022-01383-x) leading to more cooperation
* [Increasing inter-country equality](https://dan.bjorkegren.com/blog/2023/03/ai-development/) is possible as Low and Middle-Income Countries (LMICs) gain access to better info & tools

**Risks from AI:**

* AIs’ ‘black box’ nature might make it impossible for humans to understand the world if AIs automate enough processes
* AIs might create ‘increasing returns to scale’ on data, technology deployment, and human capital, widening inter-country and intra-country inequality.
* Automation of data processing can facilitate authoritarianism
* Increasing adoption of AI systems has impacts on [judicial fairness](https://verfassungsblog.de/procedural-fairness-ai/)
* Military risks: automating warfare through [lethal autonomous weapons](https://www.icrc.org/en/document/icrc-position-autonomous-weapon-systems) or the [integration of AI into nuclear command and control (NC3](https://www.cser.ac.uk/resources/autonomy-nuclear-weapons/)) poses risks to international stability
* Uncontrolled AI systems can become an [existential threat](https://oecd.ai/en/wonk/existential-threat), as they might recursively self-improve despite misalignment

**Governance gaps in AI:**

* Insufficient [democratic governance](https://www.governance.ai/post/what-do-we-mean-when-we-talk-about-ai-democratisation) of AI and data (AI access should likely not be broadened)
* No internationally implemented standards for safety and interpretability of AI behavior
* Barriers to cooperation between major AI developers

**Solutions for the governance of AI:**

* Government-funded AI alignment research
* Advocacy for AI [standard-setting ](https://www.fhi.ox.ac.uk/wp-content/uploads/Standards_-FHI-Technical-Report.pdf)
* [Mediation](https://hdcentre.org/news/release-of-draft-code-of-conduct-on-ai-enabled-military-systems/) between AI powers
* Use bans in certain cases (e.g [Lethal Autonomous Weapon Systems](https://breakingdefense.com/2023/03/not-the-right-time-us-to-push-guidelines-not-bans-at-un-meeting-on-autonomous-weapons/), [NC3](https://futureoflife.org/project/mitigating-the-risks-of-ai-integration-in-nuclear-launch/))
* Investment in cybersecurity for advanced AI models 

**Case studies in risks from AI:**

* GPT-4 [doesn't notice knowledge gaps and constantly improvises](https://time.com/6280533/ai-chatbots-improv-machines/) - requiring careful vetting of which output is real and which one is 'hallucinated'
* [AI deepfakes of Trump](https://incidentdatabase.ai/cite/499/#r2858) - and many other people
* You can find more on [incidentdatabase.ai ](https://incidentdatabase.ai)

**Prominent experts speaking about the risks and solutions:**

* [Geoff Hinton, ‘Godfather of AI’, on AI risks](https://www.bbc.co.uk/news/world-us-canada-65452940)
* [](https://www.bbc.co.uk/news/world-us-canada-65452940)[Stuart Russell, author of the main AI textbook, speaks at WEF](https://www.weforum.org/agenda/2022/01/artificial-intelligence-stuart-russell-radio-davos/)

If you would like to suggest additions or have other feedback, please email [konrad@simoninstitute.ch.](mailto:konrad@simoninstitute.ch)