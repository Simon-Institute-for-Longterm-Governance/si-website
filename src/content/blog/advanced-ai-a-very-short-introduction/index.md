---
hide: false
title: "Advanced AI: a very short introduction"
date: 2023-05-26T18:49:46.368Z
featuredImage: 21.png
authors:
  - name: Jacob Arbeid
    page: jacob-arbeid/index
isHighlighted: false
---
To assist in educating international policy actors on the need for sustainable technological development, the Simon Institute is publishing introductory briefings on key technologies. We hope that these will serve as a guide to understand the rapid developments in fields such as AI and synthetic biotechnology; we also aim for these documents to serve as living repositories of relevant information.

### Risks & opportunities from advanced artificial intelligence

**1-sentence summary:** Advanced Artificial Intelligence (AI) has transformative potential for economic growth and scientific advancement, but risks include misaligned systems, concentration of economic power, and military risks, with solutions including research, auditing, and standard-setting.

**Definitions:** AI is the science of making machines that can do human-level tasks. [Transformative AI (TAI)](https://www.openphilanthropy.org/research/some-background-on-our-views-regarding-advanced-artificial-intelligence/) are AI systems that have a transformative impact on human society (e.g., potential for 10%+ increase in annual growth rates). [Artificial general intelligence (AGI)](https://www.mckinsey.com/capabilities/operations/our-insights/an-executive-primer-on-artificial-general-intelligence) are AI systems that can do almost all tasks to human levels or better. In this document, we use ‘advanced AI’. Most of the recent advances in AI have been due to [machine learning](https://www.ibm.com/topics/machine-learning), which is a subset of AI; and reinforcement learning, which is a subset of machine learning. 

**The technical details: how artificial intelligence (specifically machine learning) works:**

* For the most advanced systems,  AI = algorithms + compute + data
* Algorithms convert data into useful outputs and allow the system to learn. AI algorithms have [not advanced much](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) since 2018. [Transformers](https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/) were a big step forward.
* Data is the information used to train the system. More data = better systems. 
* Computing power or [‘compute’](https://openai.com/research/ai-and-compute) constitutes the chips used to run the systems. AI compute is difficult to build and has a [vast supply chain](https://www.tsmc.com/english/aboutTSMC/dc_infographics_supplychain).
* Recently, most advances have come from using more compute. Scaling AI compute leads to [emergent](https://cims.nyu.edu/~sbowman/eightthings.pdf) (i.e unpredicted) advancements. This also means the cost of developing advanced AI is rapidly rising, though the potential for profits is too. 
* Advanced AI is a [‘black box’.](https://www.nature.com/articles/d41586-022-00858-1) The iterative process of AI system development means it is currently impossible to know what is happening within and to robustly align the system with human requirements. There are two types of misalignment:

  * [Outer misalignment](https://en.wikipedia.org/wiki/AI_alignment#Learning_human_values_and_preferences): humans cannot specify goals to the AI that match our aims
  * [Inner misalignment:](https://en.wikipedia.org/wiki/AI_alignment#Inner_alignment_and_emergent_goals) the AI ‘evolves’ goals through Reinforcement Learning that do not match human-specified ones. This form of misalignment is probably the bigger risk.
* The most advanced systems are ‘large language models’ like ChatGPT: these are a subset of ‘foundation models’ 

**The advanced AI landscape:**

* The most advanced systems are concentrated among a few big companies, but once a system has been trained, it is [cheap to proliferate it](https://rethinkpriorities.org/publications/background-for-understanding-the-diffusion-of-large-language-models) on consumer technology. 
* There have been [numerous](https://oecd.ai/en/wonk/documents/g20-ai-principles) [international](https://oecd.ai/en/ai-principles) [attempts](https://www.iso.org/committee/6794475.html) at AI ethics standards, with little implementation.
* The [EU AI Act](https://artificialintelligenceact.eu) is the main attempt to legislate on safe AI systems. 

**Opportunities from advanced AI:**

* [Massive economic growth](https://globalprioritiesinstitute.org/philip-trammell-and-anton-korinek-economic-growth-under-transformative-ai/) through increased productivity
* [Scientific advancement](https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/) leading to better medicine (see bio brief), solar panels etc
* [Better mediation tools](https://www.nature.com/articles/s41562-022-01383-x) leading to more global cooperation and less war
* [Increasing inter-country equality](https://dan.bjorkegren.com/blog/2023/03/ai-development/) is possible as Low and Middle Income Countries (LMICs) gain access to better info & tools

**Risks from advanced AI:**

* Misaligned AI systems are an [existential hazard](https://oecd.ai/en/wonk/existential-threat)
* AIs’ ‘black box’ nature might make it impossible for humans to make sense of our world if enough processes are automated by AIs
* Advanced AIs might create ‘increasing returns to scale’ on data, technology deployment and human capital, widening inter-country and intra-country inequality.
* Risks from facilitating authoritarianism 
* Increasing adoption of AI systems has impacts for [judicial fairness](https://verfassungsblog.de/procedural-fairness-ai/)
* Military risks: automating warfare through [lethal autonomous weapons](https://www.icrc.org/en/document/icrc-position-autonomous-weapon-systems) or the [integration of AI into nuclear command and control (NC3](https://www.cser.ac.uk/resources/autonomy-nuclear-weapons/)) poses risks to international stability

**Governance gaps in advanced AI:**

* Insufficient [democratic governance](https://www.governance.ai/post/what-do-we-mean-when-we-talk-about-ai-democratisation) of AI and of AI data (not of AI access)
* No internationally implemented standards for safety/interpretabilty (and generating these standards poses technical challenges)
* Lack of trust between major AI actors

**Solutions for the governance of advanced AI:**

* Government-funded AI alignment research
* Advocacy for AI [standard-setting ](https://www.fhi.ox.ac.uk/wp-content/uploads/Standards_-FHI-Technical-Report.pdf)
* [Mediation](https://hdcentre.org/news/release-of-draft-code-of-conduct-on-ai-enabled-military-systems/) between advanced AI powers
* Use bans in certain cases (e.g [Lethal Autonomous Weapon Systems](https://breakingdefense.com/2023/03/not-the-right-time-us-to-push-guidelines-not-bans-at-un-meeting-on-autonomous-weapons/), [NC3](https://futureoflife.org/project/mitigating-the-risks-of-ai-integration-in-nuclear-launch/))
* Investment in cybersecurity for advanced AI models 

**Case studies in risks from advanced AI:**

* [GPT-4 persuaded a human to fill a captcha](https://www.businessinsider.com/gpt4-openai-chatgpt-taskrabbit-tricked-solve-captcha-test-2023-3?r=US&IR=T)
* [AI deepfakes of Trump](https://incidentdatabase.ai/cite/499/#r2858)
* You can find more on [incidentdatabase.ai ](https://incidentdatabase.ai)

**Prominent experts speaking about the risks and solutions:**

* [Geoff Hinton, ‘Godfather of AI’, on AI risks](https://www.cbsnews.com/news/godfather-of-artificial-intelligence-weighs-in-on-the-past-and-potential-of-artificial-intelligence/)
* [Stuart Russell, author of the main AI textbook, speaks at WEF](https://www.weforum.org/agenda/2022/01/artificial-intelligence-stuart-russell-radio-davos/)